---
title: 7.4 智能体（Agent）
description: Agent 是 AI 从“被动应答”向“主动执行”演进的下一形态。它围绕一个总体任务目标，能够自主进行任务拆解、动态规划、工具调用和自我反思。其核心运行机制是 “思考-行动-观察” 循环，使其可以根据环境反馈不断调整策略。Agent 将大模型、RAG、函数调用等技术整合为一个协同工作的系统，使其从“工具箱”转变为能够独立完成复杂任务的“数字员工”。
---

如果说 RAG 是“查资料”、Function Calling 是“动手操作”，MCP 是“统一接入标准”，那么智能体（Agent）就是试图构建出一个具备“自主思考、主动规划、自动执行”能力的 AI 助手，它不再只是被动应答的“工具箱”，而是能根据目标，自己拆解任务、调用工具、甚至自我纠错的“数字员工”。

很多人第一次听到 Agent 这个词，脑海里可能会浮现出电影《黑客帝国》里的“特工”，实际上，AI 领域的 Agent 指的是具备自主决策与连续执行能力的 AI 系统。


## 7.4.1 什么是 Agent？

传统大模型只能“一问一答”，即便配合 RAG、Function Calling、大模型插件系统，仍然是“你问我答”、“你下指令我动手”。而 Agent 的出现，让 AI 从“被动回应”迈向“主动执行”，它是 AI 系统的下一代演进形态。

我们可以把 Agent 简单理解为：

- 具备清晰任务目标
- 能自主拆解任务
- 会动态规划执行路径
- 可以循环调用外部工具
- 支持状态追踪与自我反思

换句话说，Agent 不是只回答一个问题，而是围绕整体任务目标，自己判断需要干什么、该怎么干、干到什么程度算完成。

比如，当你告诉大模型：

```
“帮我总结这篇文章的核心观点。”
```

大模型会生成一段总结，事情就结束了。

但如果你告诉一个 Agent：

```
“帮我基于这个PDF文档，找出作者的主要论点、列出反驳观点、补充背景信息，整理成一份可分享的知识卡片。”
```

Agent 就会自己：

- 读取 PDF 文档
- 识别出作者观点
- 判断哪里存在争议或漏洞
- 补充缺失背景资料
- 按照预设模板，输出标准化的知识卡片

整个过程中，Agent 会多轮次与大模型、外部工具交互，必要时还会调整思路，确保任务最终完整落地。


## 7.4.2 Agent 的核心组成

要实现这样的“自主智能体”，Agent系统通常具备以下核心模块：

- 任务目标：明确 Agent 需要达成的最终任务目标，例如“撰写市场调研报告”
- 状态内存：存储历史对话、已知信息、执行记录，支持上下文追踪
- 计划规划：根据目标动态拆解任务、生成执行步骤与优先级
- 工具调用：管理工具清单，负责根据需要自动调用外部 API、函数、插件等资源
- 自我反思：在遇到失败、错误、死循环时，主动调整策略、优化执行路径
- 反馈机制：实时评估输出结果，决定是否继续、重试、切换方案

从系统架构上看，Agent 更像是一个具备微型操作系统功能的 AI 管理器，它可以调度大模型、RAG、Function Calling、插件系统、MCP 工具链，像“指挥官”一样统筹各种资源协同工作。


## 7.4.3 Agent 工作流程

每个 Agent 的设计都不尽相同，但他们的核心运行机制始终围绕着 **“思考-行动-观察”循环（Think-Act-Observe Loop）** 机制，实际应用中，不同的 Agent 实现会根据具体场景对这一流程进行优化和扩展。

当我们想让 Agent 分析一个 Python 项目的代码质量时，Agent 就会将思考-行动-观察交替执行：

```
思考(Think): 我需要分析这个Python项目的代码质量
行动(Act): 运行pylint检查代码
观察(Observe): 发现了15个警告和3个错误
思考(Think): 错误主要集中在导入和变量命名上，我需要生成具体的修复建议
行动(Act): 分析具体错误并生成修复代码
观察(Observe): 已生成修复建议
思考(Think): 现在我需要检查是否还有其他质量问题
```

这种模式让智能体能够根据每一步的结果动态调整后续策略，而不是盲目执行预定计划。

我们以“帮我写一篇关于 AI 发展的行业白皮书”为例，简单看下在 Agent 中可能的工作流程：

- 解析目标：理解任务是“撰写白皮书”，需要哪些内容结构
- 制定计划：拆解成多个子任务：资料检索 → 行业趋势总结 → 案例分析 → 格式排版
- 资源调用： 
  - 通过 RAG 检索知识库中的专业AI信息
  - 通过网络搜索 MCP Server 获取市场数据
  - 生成初稿
- 输出评估： 
  - 自检内容逻辑是否连贯
  - 若发现缺漏，回到资料检索补充
- 反复优化： 
  - 多次循环检索、生成、评估
  - 直到达到设定的“满意标准”
- 最终交付：生成一份完整、结构清晰、数据准确的白皮书文档

在这个过程中，用户不需要逐步下指令，Agent 自主安排步骤，甚至能在中途发现信息不足、思路偏差，自己调整执行路线。当然这只是一个符合定义的、常规的 Agent 工作流程。


## 7.4.4 Agent 是一个概念

正如本节标题，Agent 只是一个概念，简单来说，任何可以实现 **“思考-行动-观察”** 循环的系统都可以被称为 Agent，无论它使用什么技术。

Agent 这个概念并不是大模型时代的新词，早在上世纪 90 年代，人工智能、自动化系统、软件代理等领域就出现了 “Agent” 概念，比如简单的自动决策程序、网络环境下的信息检索系统等等。这些传统 Agent 本质上是规则驱动、功能单一、缺少"智能规划"的系统，远未达到今天大模型 Agent 的效果。

真正推动现代 Agent 概念走入大众视野、技术圈讨论的是大模型的崛起。大模型的强大理解能力和生成能力，为 Agent 提供了前所未有的“大脑”，使其能够处理复杂任务和开放场景。而我们通常理解的 Agent，其实是 AI Agent，即基于大语言模型的 Agent。

在大模型刚开始崭露头角时，人们就在想尽办法让大模型不止步于生成式问答。比如 AutoGPT，使用 AutoGPT 用户可以用自然语言设置“目标”，然后AutoGPT会根据这个目标自动拆分成子任务、调用 GPT 接口，并结合互联网搜索、文件读写等工具，连续执行任务，直至目标达成。比如我们可以用它定期爬取数据、生成报告并保存结果，无需人为逐步提示。它也是最早一批实验性质的“自主Agent”系统，尽管有很多缺陷。

在 AutoGPT 出现时，甚至还没有 Function Calling、MCP 等技术，想要实现一个 Agent，往往需要更复杂的方式去编排整个流程，Function Calling 出现后，大模型直接拥有了外部调用能力，这让 Agent 的开发变得便捷了很多，因为开发者无需额外处理工具的调用逻辑。而 MCP 的出现，更是让 Agent 的开发成本大大降低，因为开发者甚至无需自行开发工具，使用现有的 MCP Server 组合就可以为 Agent 扩展更多的能力。

随着技术的进步，现代 Agent 系统已经能够实现多轮推理、自我校正和复杂任务拆解，甚至可以构建多 Agent 协作网络，让不同专长的 Agent 协同工作，实现更复杂的任务目标。这些进展也使得 Agent 从简单的自动化工具，逐渐发展成了具有一定自主性和适应性的智能协作伙伴。


## 7.4.5 Agent VS Workflow

工作流（Workflow）的概念大家应该不会陌生，但我们这里所说的工作流，通常指的是 AI Workflow。相信很多人在接触了 Agent 后，会把 AI Agent 和 AI Workflow 搞混。

尽管 AI Agent 和 AI Workflow 都旨在基于大模型自动化完成任务，但它们在实现方式和灵活性上存在本质区别。Workflow 是预定义的、固定的流程，像是一条生产线，按照既定规则顺序执行。而 Agent 则是动态的、自适应的系统，能够根据环境变化调整策略，类似于一个有思考能力的助手。它们的核心区别在于是否会“自主”决策，当大模型可以动态决定自己的流程以及使用什么工具，自主的控制如何去完成任务时，它就是一个 Agent。

Workflow 的优势在于可预测性和稳定性，适合处理结构化、固定模式的任务。Agent 则擅长应对开放性问题和不确定环境，可以自主规划路径达成目标。在实际应用中，两者也并非对立关系，而是互补的存在。现代智能系统往往结合了 Workflow 的可靠性和 Agent 的灵活性，形成更强大的混合解决方案。
