---
title: 2.4 第一次人工智能寒冬
description: 早期AI的宏大预言未能实现，机器翻译等项目因无法处理语言的复杂性和常识而失败。符号主义遭遇了计算复杂性、知识表示困难和常识无穷性等根本技术瓶颈。这些问题导致资金链断裂和人才流失，人工智能领域由此进入了第一次长达数年的寒冬期。
---

1973年，英国数学家詹姆斯·莱特希尔（James Lighthill）发表了一份叫作人工智能通用调查（Artificial Intelligence A General Survey）的报告，给火热的AI研究泼了一盆冷水。这份后来被称为“莱特希尔报告”的文件毫不留情地指出：AI研究承诺的突破一个都没有实现。从此人工智能的发展进入了第一次寒冬！

## 2.4.1 美好愿景破灭

还记得那些雄心勃勃的预言吗？现实给了它们一记响亮的耳光：

那些AI头部研究者在10年前的预言，一个都没有实现。

例如，美国政府资助开发的俄英机器翻译项目：把The spirit is willing but the flesh is weak（心有余而力不足）翻译成了The vodka is good but the meat is rotten（伏特加很好但肉坏了）。因为词汇有多义性，俄语дух（spirit）也有“酒精”含义，плоть（flesh）也可以代指“肉类”。早期的系统无法理解文化隐喻，翻译时仅仅是把语句当作字面词汇进行替换，导致这样的笑话层出不穷，最终项目在1966年被迫叫停。

这种例子陆续出现了很多。当时的AI机器能证明复杂的数学定理，却回答不了“鸟会飞吗？”这样的简单问题。因为按照逻辑规则，企鹅也是鸟，但企鹅不会飞，答案应该是“不一定”。但其实人类这个问题可能真正想问的是“一般情况下鸟会飞吗？”这种常识性的推理十分困难。


## 2.4.2 根本性技术瓶颈

这一切的根源不在于技术不够成熟，而在于符号主义遇到了一些根本性的障碍，我们暂且把它分为以下3类。

### 1. 计算复杂性

符号主义假设智能可以通过逻辑推理实现，但现实中的推理过程远比想象的复杂。以一个简单的动物分类系统为例：

```
规则1：If 有羽毛 Then 是鸟类
规则2：If 是鸟类 AND 会游泳 Then 是水鸟
规则3：If 是水鸟 AND 脖子长 Then 可能是天鹅
规则4：If 有羽毛 AND 不会飞 Then 可能是企鹅
规则5：If 是鸟类 AND 是黑色 Then 可能是乌鸦
```

看起来只有5条规则，但当系统推理“这个动物是什么？”时，需要考虑所有可能的推理路径：

- 路径1——有羽毛→是鸟类→会游泳→是水鸟→脖子长→可能是天鹅
- 路径2——有羽毛→不会飞→可能是企鹅
- 路径3——有羽毛→是鸟类→是黑色→可能是乌鸦
- ......

随着规则数量的增加，可能的推理组合会呈指数级增长。如果有n条规则，最坏情况下需要考虑2^n种组合！当时的机器翻译项目就是这个问题的典型受害者，每个词汇的多种含义、每种语法结构的多种解释，组合起来让计算机根本无法在合理时间内找到答案。

此外，那个年代的计算机硬件远远无法支撑这种计算需求。当时计算机的随机存储器（random access memory，RAM，可简单理解为内存）的容量通常是以KB为单位的，一个中等规模的专家系统就需要数千条规则，占用大量RAM容量内存。复杂的逻辑推理需要大量计算资源，但当时计算机的中央处理器（central processing unit，CPU）的处理能力也严重不足。存储设备容量有限且访问缓慢，大规模知识库更难以实现。实时响应就更不可能了，用户往往需要等待很长时间才能得到结果，而这个等待时间也会随着计算复杂度增长而延长。

这种硬件限制让本就复杂的计算问题变得更加严重，在有限的计算能力下，实现通用智能几乎不可行。

### 2. 知识表示困难

符号主义假设现实世界可以用精确的符号表示，但现实知识往往是模糊、多义、依赖上下文的。

举一个简单例子：“天空是蓝色的”，要用符号精确表示，就会遇到以下问题：

- 晴天、阴天、黄昏、夜晚的天空颜色都不同
- 城市、乡村、沙漠、海边的天空颜色也不同
- 不同的人、色盲患者对“蓝色”的理解不同
- 天蓝、深蓝、灰蓝，哪个颜色才是“蓝色”？

更复杂的是抽象概念，比如“杯子”：

```
杯子 = 容器 + 有把手 + 用来喝水
```

而现实情况是：

- 茶杯可能没有把手
- 笔筒也是容器，但不是杯子
- 破了的杯子还算杯子吗
- 装饰用的杯子不用来喝水

人类能够轻松处理这些模糊性，但符号系统需要为每种可能性都编写明确规则。这就像试图用数学公式来精确定义“美”或“幽默”一样困难。

### 3. 常识的无穷性

符号主义假设可以通过编写足够多的规则来模拟智能，但人类的常识知识几乎是无穷的。

一个看似简单的常识“杯子用来喝水”，背后隐藏着无数条相关知识。

**物理常识**

- 杯子是空心容器
- 液体会受重力影响
- 开口向上，便于倒入液体

**材料常识**

- 杯子材质应该无毒
- 不同材质有不同特性
- 破损的杯子可能有危险

**使用常识**

- 杯子大小适合手掌握持
- 使用前应该清洗干净
- 热饮需要隔热材质

**社会常识**

- 不同场合用不同杯子
- 某些杯子有纪念意义

研究者估算，一个成年人掌握着数百万条这样的常识。要把这些全部编码成if-then规则，需要几十年甚至上百年，更糟糕的是，不同文化背景的人还有不同的常识，规则库就会更庞大。

这个时代的AI系统即使花费数年时间，也只能编码出人类常识的冰山一角。面对如此庞大的知识需求，符号主义显得力不从心。

### 4. 三重困境的叠加效应

这三重困境不是独立存在的，而是相互叠加、相互放大的：

- 知识越模糊，需要的规则越多
- 规则越多，计算复杂度越高
- 计算越复杂，对知识精确性要求越高

这形成了一个恶性循环，让符号主义陷入了无法解脱的困境，好像无论从现实技术还是理论角度来讲，通用智能都没有办法实现。

## 2.4.3 资金链断裂和人才流失

面对上述问题，投资者开始失去耐心。美国政府大幅削减AI研究资金，从每年数百万美元骤降到几十万，英国政府更是几乎完全停止了AI研究的资助。

没有资金，就留不住人才。很多AI研究者开始转向其他领域，有的去搞数据库，有的去做操作系统，那些坚持留下来的，也只能在极其有限的资源下苦苦支撑。

媒体的态度也发生了大转变。之前说AI“即将改变世界”，现在说它是“被过度炒作的泡沫”。AI研究从万众瞩目的明星，一下子沦为无人问津的边缘学科。

这就是AI历史上的第一次寒冬，从1973年一直持续到1980年。整个国际AI领域陷入了深深的反思：是符号主义的路走错了吗？

于是，面对AI领域的寒冬，一些人开始另辟蹊径...