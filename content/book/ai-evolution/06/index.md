---
title: 第六章 “驯服”大模型
---

在拥有了能力强大的预训练大模型之后，我们如何驾驭这股力量，使其不仅“能用”，而且“好用”、“可控”且“安全”？

这一过程，我们称之为“驯服”大模型。

为了让只会“续写”的模型转变为能理解并执行任务的智能助手，**指令微调（Instruction Tuning）** 应运而生。通过在海量的“指令-回应”数据上进行监督式微调，模型学会了遵循人类意图，这是使其变得“有用”的关键第一步。

在模型“听懂话”之后，还需要教会它“说对话”。**对齐优化（Alignment Optimization）** 通过 **人类反馈强化学习（RLHF）** 等技术，将人类的价值观和偏好注入模型，确保其行为负责、安全且有益，解决了“可靠性”的问题。

为了在实际应用中精确驾驭模型的输出，**可控生成（Controllable Generation）** 技术提供了一整套从软到硬的约束工具。从 **提示词工程** 、**思维链**，到 **结构化输出控制** 和 **参数级调节**，这些方法共同确保了模型输出在格式、风格和内容上的精确性和一致性。

最后探讨了如何突破大模型自身存在的知识截止、缺乏实时交互与精确计算能力等内在局限。

答案在于 **“放大模型能力”** —— 通过将模型与外部工具、实时数据源和API等进行整合，使其从一个封闭的“语言大脑”，演变为一个能够与真实世界互动的、能力更强大的开放智能体。

