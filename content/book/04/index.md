---
title: 第四章 深度学习的突破
---

本章聚焦于深度学习如何从理论走向实践，并最终在计算机视觉和序列数据处理两大核心领域引发技术革命。

故事始于 2006 年，**深度信念网络（DBN）** 的提出巧妙地克服了困扰学界多年的梯度消失难题，让构建和训练深层神经网络成为可能，从而叩开了深度学习时代的大门，使机器自动学习特征的梦想照进现实。

随后的 **计算机视觉** 领域迎来了历史性的觉醒。一方面，**ImageNet** 这一前所未有的大规模图像数据集为深度学习模型提供了充足的“养料”；另一方面，2012 年，**AlexNet** 模型凭借其深层**卷积神经网络（CNN）** 架构及对 **GPU并行计算** 的开创性使用，在 ImageNet 挑战赛中取得压倒性胜利。这一里程碑事件不仅宣告了 CNN 在图像识别领域的绝对优势，也正式开启了深度学习的黄金时代。

在 **序列数据处理** 方面，为了捕捉文本、语音等数据中的时序依赖关系，**循环神经网络（RNN）** 及其强大的变体 **长短期记忆网络（LSTM）** 应运而生，它们通过引入巧妙的记忆与门控机制，有效解决了长距离依赖问题。然而，RNN固有的串行计算瓶颈限制了其性能的进一步提升。作为突破，**注意力机制** 被提出，它赋予模型动态聚焦关键信息的能力，极大地增强了模型的性能与可解释性。

至此，深度学习的核心技术版图已初步形成，但新的挑战也随之浮现：

**“既然注意力机制如此强大，我们能否彻底摆脱RNN的串行束缚，构建一个完全基于注意力的新架构？”**

这个问题为下一场颠覆性的技术风暴埋下了伏笔。