---
title: 4.4 新的风暴即将出现
description: 2006 至 2016 的十年是深度学习的黄金时代，CNN 和 RNN 分别在视觉和序列任务上取得了革命性成果。然而，RNN 的串行处理机制成为了性能瓶颈，无法充分利用 GPU 的并行计算能力。尽管注意力机制最初只是作为 RNN 的补充，但其动态聚焦信息的能力展现了巨大潜力，引发了研究者们的思考：能否构建一个完全基于注意力机制、彻底摆脱串行依赖的模型？这一想法预示着新一轮技术风暴的到来。
---

毫无疑问 2006-2016 是属于深度学习的十年。

这十年我们见证了 DBN 的特征学习突破、CNN 的视觉革命、RNN 的序列记忆、注意力机制的动态关注。

RNN 让机器首次具备了“记忆”能力，但这种记忆受限于固定的隐状态大小，就像一个容量有限的行李箱，装得越多，早期的信息就越容易丢失。LSTM 的门控机制虽然大大改善了长距离依赖问题，让机器可以记住更长时间的信息，但本质上仍然是串行处理，就像一个人必须按顺序阅读文档，无法跳跃式地理解内容的全局关系。

而注意力机制的出现带来了革命性的思维转变：机器不再需要将所有信息压缩到一个固定向量中，而是可以动态地选择关注哪些信息。这就像给了机器一盏智能聚光灯，可以根据需要照亮最相关的内容。

但此时的注意力机制仍然只是 RNN 的“配菜”，随着 CNN 对 GPU 并行计算的成功运用，研究者们开始深刻意识到 GPU 并行计算的重要性，但 RNN 的串行特性严重限制了 GPU 并行计算优势的发挥。

很快就有研究人员开始思考，既然注意力机制如此强大，为什么还需要 RNN？能否构建一个完全基于注意力的模型？

这个想法为深度学习的下一个十年埋下了伏笔。